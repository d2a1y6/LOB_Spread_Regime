为了达到学术发表（尤其是顶级金融或微观结构期刊）的严谨性水平，模型稳定性检验（Robustness Checks）是必不可少的环节。审稿人通常会质疑：你的结果是不是数据挖掘（Data Mining）出来的巧合？

以下是一个分层级的验证清单，按“执行成本从低到高”和“逻辑深度从浅到深”排序。

------

### 第一层级：基于推断的稳定性（Inference-based Stability）

特点：不需要重新训练模型。直接利用现有的模型和测试集进行切片分析。

这也是你目前正在做的工作，成本最低，但能快速排除“局部过拟合”。

1. 时序稳定性 (Temporal Stability)
   - 日内切分 (Intraday): 上午场 (AM) vs 下午场 (PM)。验证规律是否受开盘/收盘情绪影响。
   - 周度/月度切分 (Sub-period): 第1周 vs 第2周。验证规律是否只在特定的一周存在。
2. 随机子样稳定性 (Sub-sampling Stability)
   - 从测试集中随机抽取 80% 的数据重复 100 次，计算 SHAP 交互值的分布。如果分布方差极小，说明结果对样本选择不敏感。
3. 横截面/分组稳定性 (Cross-sectional/Group Stability)
   - 按个股特征分组: 将股票池分为“高波动 vs 低波动”、“大市值 vs 小市值”、“高换手 vs 低换手”。
   - 预期: 核心规律（Spread=1动量，Spread=2反转）在所有组别中都应存在，但强度可能不同（例如小市值股票的 Spread=2 反转可能更强）。
4. 市场状态稳定性 (Regime Stability) 【目前训练集+测试集总共只有1个月，做不了】
   1. 牛熊市/波动率状态: 将测试集的时间点标记为“上涨趋势/下跌趋势”或“平静期/动荡期”。
   2. 目的: 证明该微观结构机制是市场的基础物理规律，而不是只在暴跌时才出现的异常现象。

------

### 第二层级：基于训练的稳定性 (Training-based Stability)

特点：需要使用原始数据重新训练模型，但数据本身不改动。

用于排除模型训练过程中的随机性。

1. 随机种子检验 (Seed Stability)
   - 改变 LightGBM 的 `random_state` (e.g., 42, 123, 2024, ...) 重新训练 5-10 次。
   - 标准: 每次训练出的模型，其 SHAP 交互图的形态必须一致（“五段式”结构不消失）。
2. 交叉验证稳定性 (Cross-Validation Stability)
   - 使用 5-Fold 或 10-Fold 交叉验证，而不是简单的 Train/Test 切分。展示 5 个模型的一致性。
3. 超参数敏感性 (Hyperparameter Sensitivity)
   - 轻微扰动模型的关键参数（如 `num_leaves`, `learning_rate`, `min_data_in_leaf`）。
   - 目的: 证明你的结果不是在一个极度苛刻的参数组合下“调参（Hacking）”调出来的。

------

### 第三层级：基于数据的敏感性 (Data Sensitivity)

特点：需要修改数据的定义（Feature/Label），然后重新训练。

用于证明核心逻辑的稳健性，排除特征工程的偏误。

1. 预测窗口敏感性 (Horizon Sensitivity)
   - 你现在预测的是 3秒 后的涨跌。
   - 检验: 尝试预测 1秒、5秒、10秒、30秒。
   - 预期: 随着时间拉长，微观结构的影响力（Feature Importance）应该逐渐下降，但短周期内（1-5s）核心逻辑应保持不变。
2. 标签定义敏感性 (Label Definition)
   - 你现在的 Label 可能是二分类（涨/跌）。
   - 检验: 尝试改为三分类（涨/平/跌）或回归预测（预测具体收益率数值）。
   - 目的: 证明反转效应不是因为忽略了“平盘”数据导致的统计假象。
3. 特征定义鲁棒性 (Feature Definition)
   - 把 `Micro_Mid_Spread` 换成更简单的 `Weighted_Mid_Price - Mid_Price`，或者简单的 `Spread` 档位分类变量。
   - 目的: 证明结果不依赖于某个特定的数学公式。

------

### 第四层级：模型规约/替代模型 (Model Specification)

特点：换一种算法。

这是顶级期刊非常看重的一点：Model Agnostic（模型无关性）。

1. 线性模型/逻辑回归 (Logistic Regression with Interactions)
   - 手工构建交互项特征：`X_new = LobImbalance * Spread_Dummy`。
   - 训练一个简单的逻辑回归。看交互项的系数符号是否显著为负（验证反转）。
   - 意义: 机器学习模型（LightGBM）虽然强，但黑箱。如果简单的逻辑回归也能捕捉到这个符号反转，理论解释力将极大增强。
2. 其他树模型 (XGBoost / RandomForest)
   - 用 XGBoost 复现一次。如果结果一致，说明这是树模型的共性发现，而非 LightGBM 特有的算子导致。

------

### 第五层级：伪证/安慰剂检验 (Placebo Tests)

特点：故意破坏数据结构，验证模型是否失效。

如果破坏了数据模型还能跑出结果，说明模型是错的。

1. 标签打乱 (Shuffle Labels)
   - 随机打乱 Label，特征保持不变。
   - 预期: 模型的预测能力应归零，SHAP 图应变为无规律的噪声。
2. 核心特征置换 (Feature Permutation)
   - 只打乱 `Spread` 这一列，保持其他不变。
   - 预期: 那个漂亮的“五段式”非线性交互图应该消失，退化为单一的线性关系或噪声。

------

### 建议执行路径

你现在处于 第一层级（推断稳定性）。为了达到发表标准，建议接下来的优先级如下：

1. 马上做 (High ROI):
   - Tier 1: 日内切分 (已在做)、随机子样 (Sub-sampling)。
   - Tier 4: 简单的逻辑回归 (Logistic Regression) 验证。如果简单的回归系数也能算出 `Spread=2` 时 `Imbalance` 系数为负，那理论就稳了。
2. 中期做:
   - Tier 3: 改变预测窗口 (1s, 5s)。这能画出一条漂亮的衰减曲线，放在论文里很加分。
3. 最后做 (如果审稿人挑战):
   - Tier 2: 随机种子、超参数扰动。
   - Tier 5: 安慰剂检验。